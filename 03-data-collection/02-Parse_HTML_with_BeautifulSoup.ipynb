{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse HTML with BeautifulSoup\n",
    "\n",
    "## What you will learn in this course üßêüßê\n",
    "\n",
    "Web is full of HTML pages that contain a lot of insightful data. What if you could extract it to create your own custom dataset? Opportunities would be endless! In this course, we will cover: \n",
    "\n",
    "* What is `BeautifulSoup`\n",
    "* Select parser for reading a webpage content\n",
    "* Select any HTML element within a webpage\n",
    "\n",
    "Let's get you started with `BeautifulSoup` library to crawl and harvest websites data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, make sure that `BeautifulSoup` is installed in your environment simply by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Use '!' only if you are installing directly from your notebook. \n",
    "# '!' sign tells Jupyter Notebook to interpret the following code as bash code (what you use in your terminal)\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read content with BeautifulSoup üì∞üì∞\n",
    "\n",
    "First of all, to read HTML content, you will need to _parse_ your data using the library. This is done very simply as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Instanciate BeautifulSoup class\n",
    "soup = BeautifulSoup(\"<html>data</html>\", \"html.parser\") # Here we used an HTML Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are dealing with more complex content, you have other _parsers_, especially for XML, which may be useful. Be careful, however, you will have to install the _parser_ using `pip`. These are the ones you can find:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "      <td>Parser</td>\n",
    "      <td>Typical usage</td>\n",
    "      <td>Advantages</td>\n",
    "      <td>Disadvantages</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Python‚Äôs html.parser</td>\n",
    "      <td>BeautifulSoup(markup, \"html.parser\")</td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>Batteries included</li>\n",
    "            <li>Decent speed</li>\n",
    "            <li>Lenient (as of Python 2.7.3 and 3.2.)</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>Not very lenient (before Python 2.7.3 or 3.2.2)</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>lxml‚Äôs HTML parser</td>\n",
    "      <td>BeautifulSoup(markup, \"lxml\")</td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>Very fast</li>\n",
    "            <li>Lenient</li>\n",
    "         </ul>\n",
    "         <ul>\n",
    "            <li>External C dependency</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>lxml‚Äôs XML parser</td>\n",
    "      <td>BeautifulSoup(markup, \"lxml-xml\")BeautifulSoup(markup, \"xml\")</td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>Very fast</li>\n",
    "            <li>The only currently supported XML parser</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>External C dependency</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "      <td>html5lib</td>\n",
    "      <td>BeautifulSoup(markup, \"html5lib\")</td>\n",
    "      <td>\n",
    "         <ul>\n",
    "            <li>Extremely lenient</li>\n",
    "            <li>Parses pages the same way a web browser does</li>\n",
    "            <li>Creates valid HTML5</li>\n",
    "         </ul>\n",
    "      </td>\n",
    "   <td>\n",
    "      <ul>\n",
    "         <li>Very slow</li>\n",
    "         <li>External Python dependency</li>\n",
    "      </ul>\n",
    "   </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "To install these _parsers_, you can do it using: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.6.3-cp38-cp38-manylinux2014_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.8 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.6.3\n",
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112 kB 9.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from html5lib) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.8/site-packages (from html5lib) (1.15.0)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "# Use '!' only if you are installing directly from your notebook. \n",
    "# '!' sign tells Jupyter Notebook to interpret the following code as bash code (what you use in your terminal)\n",
    "!pip install lxml\n",
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play content via BeautifulSoup\n",
    "\n",
    "The following code will be used for the rest of the course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_DOC = \"\"\"\n",
    "<html>\n",
    "  <head><title>The Dormouse's story</title></head>\n",
    "  <body>\n",
    "    <p class=\"APClassPEZ\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "    <p class=\"story\">\n",
    "      Once upon a time there were three little sisters; and their names were\n",
    "      <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "      <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "      <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "            and they lived at the bottom of a well.\n",
    "      <h1> H1 </h1  \n",
    "    </p>\n",
    "\n",
    "    <p class=\"story\">...</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new instance of `BeautifulSoup`. Here we won't need to import this class again since we did it above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of BeautifulSoup \n",
    "soup = BeautifulSoup(HTML_DOC, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find HTML content using HTML tag name üè∑Ô∏è\n",
    "\n",
    "You can find the content of an HTML page by the name of its HTML tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>The Dormouse's story</title></head>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find <head> tag contained within HTML_DOC\n",
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>The Dormouse's story</title>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find <title> tag contained within HTML_DOC\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.title.parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"APClassPEZ\"><b>The Dormouse's story</b></p>\n",
      "['APClassPEZ']\n"
     ]
    }
   ],
   "source": [
    "print(soup.p)\n",
    "print(soup.p['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a parent's element üë©‚Äçüëß\n",
    "\n",
    "You can find a parent element using loops:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the first <a> tag within HTML_DOC\n",
    "link = soup.a\n",
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"story\">\n",
       "       Once upon a time there were three little sisters; and their names were\n",
       "       <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "       <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "       <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "       and they lived at the bottom of a well.\n",
       "     </p>,\n",
       " <body>\n",
       " <p class=\"title\"><b>The Dormouse's story</b></p>\n",
       " <p class=\"story\">\n",
       "       Once upon a time there were three little sisters; and their names were\n",
       "       <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "       <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "       <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "       and they lived at the bottom of a well.\n",
       "     </p>\n",
       " <p class=\"story\">...</p>\n",
       " </body>,\n",
       " <html>\n",
       " <head><title>The Dormouse's story</title></head>\n",
       " <body>\n",
       " <p class=\"title\"><b>The Dormouse's story</b></p>\n",
       " <p class=\"story\">\n",
       "       Once upon a time there were three little sisters; and their names were\n",
       "       <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "       <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "       <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "       and they lived at the bottom of a well.\n",
       "     </p>\n",
       " <p class=\"story\">...</p>\n",
       " </body>\n",
       " </html>,\n",
       " \n",
       " <html>\n",
       " <head><title>The Dormouse's story</title></head>\n",
       " <body>\n",
       " <p class=\"title\"><b>The Dormouse's story</b></p>\n",
       " <p class=\"story\">\n",
       "       Once upon a time there were three little sisters; and their names were\n",
       "       <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       "       <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
       "       <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
       "       and they lived at the bottom of a well.\n",
       "     </p>\n",
       " <p class=\"story\">...</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# link.parents creates a generator (more info => https://wiki.python.org/moin/Generators)\n",
    "## We can use python built-in function list() to see what is inside it\n",
    "list(link.parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent 0 is: p\n",
      "<class 'bs4.element.Tag'>\n",
      "Parent 1 is: body\n",
      "<class 'bs4.element.Tag'>\n",
      "Parent 2 is: html\n",
      "<class 'bs4.element.Tag'>\n",
      "Parent 3 is: [document]\n",
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Let's now Loop through all parents of link\n",
    "# Let's also use enumerate() built-in function to get the index number of each iteration\n",
    "for i, parent in enumerate(link.parents):\n",
    "    # if we have no more parents\n",
    "    if parent is None:\n",
    "        print(parent)\n",
    "    else:\n",
    "        print(\"Parent {} is: {}\".format(i, parent.name)) # parent.name will give only the element name as output\n",
    "        print(type(parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find a sibling's element üéé üéé\n",
    "\n",
    "You can select an element's next siblings with `.next_siblings` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",\n",
      "      \n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      " and\n",
      "      \n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n",
      ";\n",
      "            and they lived at the bottom of a well.\n",
      "      \n",
      "<h1> H1 </h1>\n",
      "\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all the next <a> tag\n",
    "for sibling in soup.a.next_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, you can select an element's previous siblings with `.previous_siblings` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and\n",
      "      \n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n",
      ",\n",
      "      \n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
      "\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "# Let's use .find() method to select <a> tag with id=\"link3\"\n",
    "# Then display all its previous siblings\n",
    "for sibling in soup.find(id=\"link3\").previous_siblings:\n",
    "    print(sibling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all items that meet a specific condition ‚ùì\n",
    "\n",
    "There is a very handy function in beautifulsoup: `.find_all()` which fetch all the elements of an HTML page that meet certain criteria. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<title>The Dormouse's story</title>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all elements named title\n",
    "soup.find_all(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"title\"><b>The Dormouse's story</b></p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all p elements with the class \"title\"\n",
    "soup.find_all(\"p\", \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all <a> tags\n",
    "soup.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all elements with id=\"link2\"\n",
    "soup.find_all(id=\"link2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n      Once upon a time there were three little sisters; and their names were\\n      '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all strings that contain \"sisters\"\n",
    "## Here we use re package which is used for regular expression \n",
    "## More info here => https://docs.python.org/3/library/re.html\n",
    "import re\n",
    "\n",
    "soup.find(string=re.compile(\"sisters\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find elements using CSS üßë‚Äçüé®üßë‚Äçüé®\n",
    "\n",
    "Finally, content can be found via CSS selectors, by using the `.select()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
       " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all <a> tags with class of \"sister\"\n",
    "soup.select(\"a.sister\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"a.href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all <a> with id=\"link1\"\n",
    "soup.select(\"a#link1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deeply nested elements, you can specify a path, just like you would do in plain CSS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all <a> with id=\"link1\" that are contained within <p> with class=\"story\"\n",
    "## NB this is exactly like writing soup.select(\"a#link1\")\n",
    "soup.select(\"p.story a#link1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text üìÉüìÉ\n",
    "You can use `.get_text()` to extract the encapsulated text within an HTML tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elsie'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the list item that soup.select(\"a#link1\") outputs\n",
    "## Use get_text() to get only the string part \n",
    "soup.select(\"a#link1\")[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsie', 'Lacie', 'Tillie']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use list comprehensions to select all text from all <a> tags of class=\"sister\"\n",
    "[a.get_text() for a in soup.select(\"a.sister\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elsie', 'Lacie', 'Tillie']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.get_text() for a in soup.select(\"a.sister\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://example.com/elsie',\n",
       " 'http://example.com/lacie',\n",
       " 'http://example.com/tillie']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.get('href') for a in soup.select(\"a.sister\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract a property üîóüîó\n",
    "\n",
    "Sometimes, it is extremely useful to extract the value of a property within an HTML tag. For example, you might want to extract all the URLs of a given webpage. You can use the `.get()` method to extract a given property from an element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://example.com/elsie'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract href property from <a> tags with id=\"link1\"\n",
    "soup.select(\"a#link1\")[0].get('href')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources üìö üìö\n",
    "\n",
    "- <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\" target=\"_blank\">BeautifulSoup documentation</a>\n",
    "- <a href=\"https://pypi.org/project/beautifulsoup4/\" target=\"_blank\">pip install beautifulsoup4</a> \n",
    "- <a href=\"https://docs.python.org/3/library/re.html\" target=\"_blank\">re</a>\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Web_scraping\" target=\"_blank\">Web Scraping</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
