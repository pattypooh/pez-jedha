{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_types = {'Store': np.int8,\n",
    "             'Date':str,\n",
    "             'Weekly_Sales':np.float64,\n",
    "             'Holiday_Flag':np.float16,\n",
    "             'Temperature':np.float16,\n",
    "             'Fuel_Price':np.float16,\n",
    "             'CPI':np.float16,\n",
    "            'Unemployment':np.float16,}\n",
    "data = pd.read_csv('./../data/raw/Walmart_Store_sales.csv', date_parser=True, usecols=col_types.keys(), dtype=col_types)#,  usecols=col_types.keys(), dtype=col_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Store         150 non-null    int8   \n",
      " 1   Date          132 non-null    object \n",
      " 2   Weekly_Sales  136 non-null    float64\n",
      " 3   Holiday_Flag  138 non-null    float16\n",
      " 4   Temperature   132 non-null    float16\n",
      " 5   Fuel_Price    136 non-null    float16\n",
      " 6   CPI           138 non-null    float16\n",
      " 7   Unemployment  135 non-null    float16\n",
      "dtypes: float16(5), float64(1), int8(1), object(1)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>1.360000e+02</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>138.00000</td>\n",
       "      <td>135.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.866667</td>\n",
       "      <td>1.249536e+06</td>\n",
       "      <td>0.079712</td>\n",
       "      <td>61.406250</td>\n",
       "      <td>3.322266</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>7.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.231191</td>\n",
       "      <td>6.474630e+05</td>\n",
       "      <td>0.271973</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>0.478271</td>\n",
       "      <td>40.28125</td>\n",
       "      <td>1.577148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.689290e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.796875</td>\n",
       "      <td>2.513672</td>\n",
       "      <td>126.12500</td>\n",
       "      <td>5.144531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.050757e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.593750</td>\n",
       "      <td>2.851562</td>\n",
       "      <td>132.00000</td>\n",
       "      <td>6.597656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.261424e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>3.451172</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>7.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.750000</td>\n",
       "      <td>1.806386e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.312500</td>\n",
       "      <td>3.707031</td>\n",
       "      <td>214.87500</td>\n",
       "      <td>8.148438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.771397e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.625000</td>\n",
       "      <td>4.191406</td>\n",
       "      <td>227.00000</td>\n",
       "      <td>14.312500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "count  150.000000  1.360000e+02    138.000000   132.000000  136.000000   \n",
       "mean     9.866667  1.249536e+06      0.079712    61.406250    3.322266   \n",
       "std      6.231191  6.474630e+05      0.271973    18.375000    0.478271   \n",
       "min      1.000000  2.689290e+05      0.000000    18.796875    2.513672   \n",
       "25%      4.000000  6.050757e+05      0.000000    45.593750    2.851562   \n",
       "50%      9.000000  1.261424e+06      0.000000    63.000000    3.451172   \n",
       "75%     15.750000  1.806386e+06      0.000000    76.312500    3.707031   \n",
       "max     20.000000  2.771397e+06      1.000000    91.625000    4.191406   \n",
       "\n",
       "             CPI  Unemployment  \n",
       "count  138.00000    135.000000  \n",
       "mean   180.00000      7.601562  \n",
       "std     40.28125      1.577148  \n",
       "min    126.12500      5.144531  \n",
       "25%    132.00000      6.597656  \n",
       "50%    198.00000      7.468750  \n",
       "75%    214.87500      8.148438  \n",
       "max    227.00000     14.312500  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(data):\n",
    "    return pd.concat([data.isna().sum(), \n",
    "        np.round(data.isna().sum()*100/data.shape[0])], \n",
    "        axis=1).rename({0:'count_missing', 1:'%_missing'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_missing</th>\n",
       "      <th>%_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>18</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>18</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fuel_Price</th>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPI</th>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployment</th>\n",
       "      <td>15</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count_missing  %_missing\n",
       "Store                     0        0.0\n",
       "Date                     18       12.0\n",
       "Weekly_Sales             14        9.0\n",
       "Holiday_Flag             12        8.0\n",
       "Temperature              18       12.0\n",
       "Fuel_Price               14        9.0\n",
       "CPI                      12        8.0\n",
       "Unemployment             15       10.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Store type to str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'Store':'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty dates\n",
    "#data = data.dropna(subset=['Weekly_Sales', 'Date'], axis=0)\n",
    "data = data.dropna(subset=['Weekly_Sales'], axis=0)\n",
    "X= data.drop('Weekly_Sales', axis=1)\n",
    "y= data.loc[:,'Weekly_Sales']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Train data')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(28, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Train data')\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features from the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Create a Transformer to use it in the pipeline\n",
    "class DateAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, date_ix = 1):\n",
    "        self.date_ix = date_ix\n",
    "        self.new_features = []\n",
    "    def fit(self, X, y=None):\n",
    "        return self #Nothing else to do\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        X is an array-like of shape (n_samples, 1).  1D array\n",
    "        '''\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            dates = pd.to_datetime(X.iloc[:, self.date_ix])\n",
    "        else:\n",
    "            dates = pd.to_datetime(X)\n",
    "        #dates = pd.to_datetime(X) # old code --> dates = pd.to_datetime(X[self.date_ix])\n",
    "        year=dates.dt.year #Because of null values, year could be NA\n",
    "        month=dates.dt.month#.astype('Int16')\n",
    "        day=dates.dt.day#.astype('Int16')\n",
    "        dayofweek=dates.dt.dayofweek#.astype('Int16')\n",
    "        weekday=dates.dt.strftime(\"%A\")\n",
    "        week=dates.dt.isocalendar().week.astype(np.float64)\n",
    "        self.new_features=['year', 'month', 'day', 'dayofweek', 'week']\n",
    "        X_without_Date = X.drop('Date', axis=1)\n",
    "        return np.c_[X_without_Date, year.values, month.values, day.values, dayofweek.values, week.values]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "attr_adder = DateAttributesAdder(date_ix = 1)\n",
    "attr_adder.transform(pd.DataFrame(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_date(df:pd.DataFrame):\n",
    "    data = df.copy()\n",
    "    if data.dtypes['Date'] == 'object':\n",
    "        data['Date'] = pd.to_datetime(data['Date'])\n",
    "    data['year']=data['Date'].dt.year #Because of null values,\n",
    "    data['month']=data['Date'].dt.month#.astype(np.float16)\n",
    "    data['day']=data['Date'].dt.day#.astype('Int16')\n",
    "    data['dayOfWeek']=data['Date'].dt.dayofweek#.astype('Int16')\n",
    "    data['weekday']=data['Date'].dt.strftime(\"%A\")\n",
    "    data['week']=data['Date'].dt.isocalendar().week.astype(np.float16)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "explode_date(X_train).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre/processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_idx = [2, 3, 4, 5, 6 ]\n",
    "cat_idx = [0] #Store\n",
    "date_idx = [1] #not used.\n",
    "num_features = ['Holiday_Flag','Temperature', 'Fuel_Price', 'CPI', 'Unemployment']#, 'year', 'month','day', 'dayOfWeek', 'week']\n",
    "cat_features = ['Store']\n",
    "date_feature = ['Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transformer for extra features from Date\n",
    "date_transformer = Pipeline([\n",
    "       # ('imputer_date', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('attr_adder', DateAttributesAdder(date_ix=0)),\n",
    "        ('imputer_date', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# transformer for numerical features\n",
    "num_transformer = Pipeline([\n",
    "        ('imputer_num', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "# transformer for categorical features\n",
    "cat_transformer = Pipeline([\n",
    "        ('imputer_cat', SimpleImputer(strategy = 'most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('date', date_transformer, date_feature), #explode the Date feature into many\n",
    "        ('categoricals', cat_transformer, cat_features),\n",
    "        ('numericals', num_transformer, num_features)\n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans_X_train = preprocessor.transformers[0][1][1].get_feature_names(['Store', 'Holiday_Flag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Preprocessing + Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Pipeline([\n",
    "        ('preprocessing', preprocessor),\n",
    "        ('lin_reg', LinearRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('date',\n",
       "                                                  Pipeline(steps=[('attr_adder',\n",
       "                                                                   DateAttributesAdder(date_ix=0)),\n",
       "                                                                  ('imputer_date',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Date']),\n",
       "                                                 ('categoricals',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Store']),\n",
       "                                                 ('numericals',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Holiday_Flag',\n",
       "                                                   'Temperature', 'Fuel_Price',\n",
       "                                                   'CPI', 'Unemployment'])])),\n",
       "                ('lin_reg', LinearRegression())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = full_pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score train\n",
      "0.9730436431571775\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 score train')\n",
    "print(r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score test\n",
      "0.9203041286997493\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 score test')\n",
    "y_pred_test = full_pipeline.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overfitting\n"
     ]
    }
   ],
   "source": [
    "print('Overfitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': Pipeline(steps=[('attr_adder', DateAttributesAdder(date_ix=0)),\n",
       "                 ('imputer_date', SimpleImputer(strategy='most_frequent')),\n",
       "                 ('scaler', StandardScaler())]),\n",
       " 'categoricals': Pipeline(steps=[('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
       "                 ('onehot', OneHotEncoder(handle_unknown='ignore'))]),\n",
       " 'numericals': Pipeline(steps=[('imputer_num', SimpleImputer(strategy='median')),\n",
       "                 ('scaler', StandardScaler())])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.steps[0][1].named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('attr_adder', DateAttributesAdder(date_ix=0)),\n",
       "                ('imputer_date', SimpleImputer(strategy='most_frequent')),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.steps[0][1].named_transformers_['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder = full_pipeline.named_steps['preprocessing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Attribute, coefficient)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('1', 191349.44822725153),\n",
       " ('10', 854691.8726457651),\n",
       " ('11', 15582.657957382222),\n",
       " ('12', 387817.33901325124),\n",
       " ('13', 824076.1728437055),\n",
       " ('14', 853687.4335406728),\n",
       " ('15', -414695.6321716911),\n",
       " ('16', -838749.1773393239),\n",
       " ('17', -288846.75614638906),\n",
       " ('18', 80349.52139502822),\n",
       " ('19', 339620.2935463835),\n",
       " ('2', 622989.7821567365),\n",
       " ('20', 597847.6894229373),\n",
       " ('3', -990309.7443166486),\n",
       " ('4', 951063.7128448143),\n",
       " ('5', -1107780.0121493563),\n",
       " ('6', 206329.54215408748),\n",
       " ('7', -764377.3721606745),\n",
       " ('8', -577491.3481664141),\n",
       " ('9', -943155.4232975498),\n",
       " ('CPI', 129107.62941202147),\n",
       " ('Fuel_Price', -7548.7940198528895),\n",
       " ('Holiday_Flag', -17645.734993297257),\n",
       " ('Temperature', -25277.005882919908),\n",
       " ('Unemployment', -95055.33138529448),\n",
       " ('day', -31123.827691664654),\n",
       " ('dayofweek', -15030.710846604537),\n",
       " ('month', -52882.014998182145),\n",
       " ('week', 60169.953119468264),\n",
       " ('year', -43446.442041053015)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_atrib = full_pipeline.steps[0][1].named_transformers_['date'][0].new_features\n",
    "cat_encoder = full_pipeline.steps[0][1].named_transformers_['categoricals'][1]\n",
    "cat_attr = list(cat_encoder.categories_[0])\n",
    "\n",
    "attributes = extra_atrib + cat_attr + num_features\n",
    "attributes\n",
    "print('(Attribute, coefficient)')\n",
    "sorted(zip(attributes, full_pipeline.steps[1][1].coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=1.5)\n",
      "----------------------------\n",
      "model score train: 0.9209\n",
      "model score test: 0.8459\n",
      "\n",
      "\n",
      "Lasso(alpha=100, max_iter=500, tol=0.005)\n",
      "----------------------------\n",
      "model score train: 0.9730\n",
      "model score test: 0.9196\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    Ridge(alpha=1.5),\n",
    "    Lasso(alpha =100, max_iter=500, tol=0.005),\n",
    "    ]\n",
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', regressor)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(regressor)\n",
    "    print('----------------------------')\n",
    "    print(\"model score train: %.4f\" % pipe.score(X_train, y_train))\n",
    "    print(\"model score test: %.4f\" % pipe.score(X_test, y_test))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carmina/miniconda3/envs/pez-jedha/lib/python3.7/site-packages/sklearn/linear_model/_stochastic_gradient.py:1211: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor()\n",
      "model score train: 0.963\n",
      "model score test: 0.910\n",
      "RandomForestRegressor()\n",
      "model score train: 0.953\n",
      "model score test: 0.697\n",
      "AdaBoostRegressor()\n",
      "model score train: 0.664\n",
      "model score test: 0.457\n"
     ]
    }
   ],
   "source": [
    "regressors = [\n",
    "    SGDRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    AdaBoostRegressor(),\n",
    "    ]\n",
    "for regressor in regressors:\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', regressor)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    print(regressor)\n",
    "    print(\"model score train: %.3f\" % pipe.score(X_train, y_train))\n",
    "    print(\"model score test: %.3f\" % pipe.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importances with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('regressor', RandomForestRegressor(max_depth=8, min_samples_split=6))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('date',\n",
       "                                                  Pipeline(steps=[('attr_adder',\n",
       "                                                                   DateAttributesAdder(date_ix=0)),\n",
       "                                                                  ('imputer_date',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Date']),\n",
       "                                                 ('categoricals',\n",
       "                                                  Pipeline(steps=[('imputer_cat',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Store']),\n",
       "                                                 ('numericals',\n",
       "                                                  Pipeline(steps=[('imputer_num',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Holiday_Flag',\n",
       "                                                   'Temperature', 'Fuel_Price',\n",
       "                                                   'CPI', 'Unemployment'])])),\n",
       "                ('regressor',\n",
       "                 RandomForestRegressor(max_depth=8, min_samples_split=6))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score train\n",
      "0.9095736381655434\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 score train')\n",
    "print(r2_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score test\n",
      "0.6412295883052653\n"
     ]
    }
   ],
   "source": [
    "print(f'R2 score test')\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "print(r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.16623501756663167, '3'),\n",
       " (0.11394060595711955, 'CPI'),\n",
       " (0.10446279733891618, 'Fuel_Price'),\n",
       " (0.09057083239731245, '5'),\n",
       " (0.08735210120840266, '14'),\n",
       " (0.05999207980916713, 'Unemployment'),\n",
       " (0.05956160106191121, 'Temperature'),\n",
       " (0.032425425594753754, '16'),\n",
       " (0.03218470427036486, '7'),\n",
       " (0.028146016261330602, '13'),\n",
       " (0.025080386699702174, '15'),\n",
       " (0.020014165115044096, '8'),\n",
       " (0.017630996592048774, '17'),\n",
       " (0.017260387450303456, '9'),\n",
       " (0.01693752906508953, '2'),\n",
       " (0.016454504388181336, 'week'),\n",
       " (0.015396961438932964, 'month'),\n",
       " (0.014044919097871792, '4'),\n",
       " (0.012338109930828432, '1'),\n",
       " (0.012265944344787906, 'dayofweek'),\n",
       " (0.010836000836434037, '20'),\n",
       " (0.00957516989346944, '19'),\n",
       " (0.009390794217494197, 'day'),\n",
       " (0.008116432880060667, '10'),\n",
       " (0.006672980359420806, '6'),\n",
       " (0.003939796123277337, 'year'),\n",
       " (0.0038668486445038747, '12'),\n",
       " (0.002921635787942191, '11'),\n",
       " (0.001224060324798784, '18'),\n",
       " (0.0011611953438982535, 'Holiday_Flag')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(pipe.named_steps['regressor'].feature_importances_,attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To improve the model (either linear regression or RandomForest), try the options: <br>\n",
    "    - Get more data, with only 150, it's difficult to have a good model <br>\n",
    "    - Drop getting rid of uninformative features like the month, the Holiday_Flag, Stores with few data"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d228d5b469f0fe34efcdbd21b769eeeb85df70f39f109e1cdb9fb653250c805e"
  },
  "kernelspec": {
   "display_name": "kernel-pez-jedha",
   "language": "python",
   "name": "kernel-pez-jedha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
